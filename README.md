# CSNLP_Abductive-Commonsense-Reasoning-in-LLMs-with-Chain-of-Thought-Prompting

Welcome to the CSNLP_Abductive-Commonsense-Reasoning-in-LLMs-with-Chain-of-Thought-Prompting project!

Previous studies on the abductive common sense reasoning capabilities of modern  large language models (LLMs) often overlook the potential impact of prompting techniques, such as Chain of Thought (CoT). In this study, we explore how can such prompting techniques enhance the abductive reasoning skills of LLMs. We establish a baseline for multiple models performance in binary classification tasks using the ART datasets in a zero shot setting , which require selecting the most plausible explanation from given scenarios. We evaluate Llama3 and other models using different prompting techniques, such as Chain-of-Thought. Our goal is to analyse the influence prompting techniques can have on the abductive common sense reasoning skills of modern LLMs aiming to uncover why these strategies enhance or fail to enhance model performance.

For reproducibility, we used a function that fixes all the seeds and set all the hyperparameters in the notebooks.


## Features
- Abductive reasoning using LLMs
- Chain of Thought Prompting technique
- Self-Consistency Prompting technique

## Installation
To use this project, follow these steps:
1. Clone the repository: `git clone https://github.com/Stebi-Lab/CSNLP_Abductive-Commonsense-Reasoning-in-LLMs-with-Chain-of-Thought-Prompting.git`
2. Run the cells inside the notebooks




